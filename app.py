# app.py
import streamlit as st
import pandas as pd

from db import init_db, log_prediction, fetch_all_predictions
from models import predict_sentiment
from monitoring import compute_basic_metrics, build_charts

# Initialisation DB
init_db()

st.set_page_config(
    page_title="NLP Monitoring Playground",
    layout="wide"
)

st.sidebar.title("NLP Monitoring Playground")
page = st.sidebar.radio("Navigation", ["ðŸ”¤ PrÃ©diction", "ðŸ“Š Monitoring", "ðŸ“š Ã€ propos"])

if page == "ðŸ”¤ PrÃ©diction":
    st.title("ðŸ”¤ Analyse de sentiment avec un Transformer")

    text = st.text_area("Tape un texte (FR ou autre) :", height=150)

    true_label = st.selectbox(
        "Si tu veux, donne la 'vraie' note (1â€“5 Ã©toiles) pour calculer les mÃ©triques :",
        options=[None, 1, 2, 3, 4, 5],
        format_func=lambda x: "Je ne sais pas / je ne mets rien" if x is None else f"{x} â˜…"
    )

    if st.button("Analyser"):
        if not text.strip():
            st.warning("Merci de renseigner un texte.")
        else:
            pred_label, confidence, probs = predict_sentiment(text)

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("RÃ©sultat du modÃ¨le")
                st.metric("Note prÃ©dite", f"{pred_label} â˜…")
                st.metric("Confiance", f"{confidence*100:.1f} %")

            with col2:
                st.subheader("Confiance du modÃ¨le")
                st.metric("Score", f"{confidence*100:.1f} %")


            # Log dans la BDD
            log_prediction(
                text=text,
                true_label=true_label,
                pred_label=pred_label,
                confidence=confidence
            )
            st.success("PrÃ©diction enregistrÃ©e dans la base pour le monitoring âœ…")

elif page == "ðŸ“Š Monitoring":
    st.title("ðŸ“Š Monitoring du modÃ¨le")

    rows = fetch_all_predictions()
    if not rows:
        st.info("Aucune prÃ©diction pour lâ€™instant. Va dâ€™abord dans lâ€™onglet 'PrÃ©diction'.")
    else:
        df = pd.DataFrame(rows)
        st.subheader("Journal des prÃ©dictions")
        st.dataframe(df[["timestamp", "text", "true_label", "pred_label", "confidence"]])

        metrics = compute_basic_metrics(df)
        st.subheader("MÃ©triques globales")

        col1, col2, col3 = st.columns(3)
        col1.metric("Nombre d'exemples", metrics["n"])
        col2.metric("Accuracy (avec true_label)", f"{metrics['accuracy']*100:.1f} %" if metrics["accuracy"] is not None else "N/A")
        col3.metric("Confiance moyenne", f"{metrics['mean_conf']*100:.1f} %")

        st.subheader("Visualisations")
        build_charts(df)

elif page == "ðŸ“š Ã€ propos":
    st.title("ðŸ“š Ã€ propos du projet")
    st.markdown("""
Ce projet est un **playground de monitoring de modÃ¨le NLP** :
- ModÃ¨le : Transformer prÃ©-entraÃ®nÃ© (*sentiment analysis*).
- Base : SQLite.
- Interface : Streamlit.
- Monitoring : mÃ©triques + graphiques, mis Ã  jour au fil des prÃ©dictions.

Il a Ã©tÃ© conÃ§u comme projet d'auto-formation pour :
- MLOps (monitoring, journaux de prÃ©diction),
- Bases de donnÃ©es,
- MÃ©triques d'Ã©valuation,
- Transformers.
""")
